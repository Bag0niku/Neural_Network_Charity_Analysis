{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYjZXv0JOQuR8cy7bQW4wT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bag0niku/Neural_Network_Charity_Analysis/blob/main/Charity_Funding_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the Environment"
      ],
      "metadata": {
        "id": "rzAKNSt1sn22"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuEbNawDTn-9",
        "outputId": "353d15d3-f039-4ccb-c93b-eac0513b8ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.1.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.9.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.18.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.49.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.1)\n"
          ]
        }
      ],
      "source": [
        "# %matplotlib\n",
        "# Import our dependencies\n",
        "!pip install keras-tuner\n",
        "import kerastuner as kt\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import os\n",
        "\n",
        "filepath = \"https://nn-charity-analysis.s3.us-west-2.amazonaws.com/charity_data.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and clean the data for use in the Neural Network Model\n",
        "\n",
        "The training and testing data needs to be numeric and scaled. "
      ],
      "metadata": {
        "id": "XM1IERRNsvLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the data into a dataframe\n",
        "df = pd.read_csv(filepath)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "X4g5lUobQa3Z",
        "outputId": "df9bfbb0-780a-4efd-f17f-996e1d76f696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             EIN                                               NAME  \\\n",
              "0       10520599                       BLUE KNIGHTS MOTORCYCLE CLUB   \n",
              "1       10531628             AMERICAN CHESAPEAKE CLUB CHARITABLE TR   \n",
              "2       10547893                 ST CLOUD PROFESSIONAL FIREFIGHTERS   \n",
              "3       10553066                     SOUTHSIDE ATHLETIC ASSOCIATION   \n",
              "4       10556103           GENETIC RESEARCH INSTITUTE OF THE DESERT   \n",
              "...          ...                                                ...   \n",
              "34294  996009318              THE LIONS CLUB OF HONOLULU KAMEHAMEHA   \n",
              "34295  996010315           INTERNATIONAL ASSOCIATION OF LIONS CLUBS   \n",
              "34296  996012607                                PTA HAWAII CONGRESS   \n",
              "34297  996015768  AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...   \n",
              "34298  996086871                           WATERHOUSE CHARITABLE TR   \n",
              "\n",
              "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
              "0                  T10       Independent          C1000    ProductDev   \n",
              "1                   T3       Independent          C2000  Preservation   \n",
              "2                   T5  CompanySponsored          C3000    ProductDev   \n",
              "3                   T3  CompanySponsored          C2000  Preservation   \n",
              "4                   T3       Independent          C1000     Heathcare   \n",
              "...                ...               ...            ...           ...   \n",
              "34294               T4       Independent          C1000    ProductDev   \n",
              "34295               T4  CompanySponsored          C3000    ProductDev   \n",
              "34296               T3  CompanySponsored          C2000  Preservation   \n",
              "34297               T5       Independent          C3000    ProductDev   \n",
              "34298               T3       Independent          C1000  Preservation   \n",
              "\n",
              "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
              "0       Association       1              0                      N      5000   \n",
              "1      Co-operative       1         1-9999                      N    108590   \n",
              "2       Association       1              0                      N      5000   \n",
              "3             Trust       1    10000-24999                      N      6692   \n",
              "4             Trust       1  100000-499999                      N    142590   \n",
              "...             ...     ...            ...                    ...       ...   \n",
              "34294   Association       1              0                      N      5000   \n",
              "34295   Association       1              0                      N      5000   \n",
              "34296   Association       1              0                      N      5000   \n",
              "34297   Association       1              0                      N      5000   \n",
              "34298  Co-operative       1          1M-5M                      N  36500179   \n",
              "\n",
              "       IS_SUCCESSFUL  \n",
              "0                  1  \n",
              "1                  1  \n",
              "2                  0  \n",
              "3                  1  \n",
              "4                  1  \n",
              "...              ...  \n",
              "34294              0  \n",
              "34295              0  \n",
              "34296              0  \n",
              "34297              1  \n",
              "34298              0  \n",
              "\n",
              "[34299 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-921adb10-7418-4cb1-8fa6-e1561e69f213\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>996009318</td>\n",
              "      <td>THE LIONS CLUB OF HONOLULU KAMEHAMEHA</td>\n",
              "      <td>T4</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>996010315</td>\n",
              "      <td>INTERNATIONAL ASSOCIATION OF LIONS CLUBS</td>\n",
              "      <td>T4</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>996012607</td>\n",
              "      <td>PTA HAWAII CONGRESS</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>996015768</td>\n",
              "      <td>AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...</td>\n",
              "      <td>T5</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>996086871</td>\n",
              "      <td>WATERHOUSE CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1M-5M</td>\n",
              "      <td>N</td>\n",
              "      <td>36500179</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows Ã— 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-921adb10-7418-4cb1-8fa6-e1561e69f213')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-921adb10-7418-4cb1-8fa6-e1561e69f213 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-921adb10-7418-4cb1-8fa6-e1561e69f213');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look for null values and incorrect datatypes\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBBL0sf-j9EG",
        "outputId": "d1ad99dc-283d-4c64-c253-19b537853853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34299 entries, 0 to 34298\n",
            "Data columns (total 12 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   EIN                     34299 non-null  int64 \n",
            " 1   NAME                    34299 non-null  object\n",
            " 2   APPLICATION_TYPE        34299 non-null  object\n",
            " 3   AFFILIATION             34299 non-null  object\n",
            " 4   CLASSIFICATION          34299 non-null  object\n",
            " 5   USE_CASE                34299 non-null  object\n",
            " 6   ORGANIZATION            34299 non-null  object\n",
            " 7   STATUS                  34299 non-null  int64 \n",
            " 8   INCOME_AMT              34299 non-null  object\n",
            " 9   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
            " 10  ASK_AMT                 34299 non-null  int64 \n",
            " 11  IS_SUCCESSFUL           34299 non-null  int64 \n",
            "dtypes: int64(4), object(8)\n",
            "memory usage: 3.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of unique values in each column.\n",
        "df.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4yPF4SWQhTs",
        "outputId": "4cb6295d-dd1b-4f88-ec63-2ac81876bcbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EIN                       34299\n",
              "NAME                      19568\n",
              "APPLICATION_TYPE             17\n",
              "AFFILIATION                   6\n",
              "CLASSIFICATION               71\n",
              "USE_CASE                      5\n",
              "ORGANIZATION                  4\n",
              "STATUS                        2\n",
              "INCOME_AMT                    9\n",
              "SPECIAL_CONSIDERATIONS        2\n",
              "ASK_AMT                    8747\n",
              "IS_SUCCESSFUL                 2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently have:\n",
        "\n",
        "Features: \n",
        "*   APPLICATION_TYPE (Categorical string)\n",
        "*   AFFILIATION      (Categorical string)\n",
        "*   CLASSIFICATION   (Categorical string)\n",
        "*   USE_CASE         (Categorical string)\n",
        "*   ORGANIZATION     (Categorical string)\n",
        "*   STATUS           (Numeric T/F)\n",
        "*   INCOME_AMT       (Categorical string)\n",
        "*   SPECIAL_CONSIDERATIONS (Numeric T/F)\n",
        "*   ASK_AMT          (Number)\n",
        "\n",
        "Target: \n",
        "*   IS_SUCCESSFUL    (Numeric T/F)\n",
        "\n",
        "\n",
        "What we want the neural network to process all the features as numeric T/F columns, including the categorical strings, this technique is also known as One Hot Encoding."
      ],
      "metadata": {
        "id": "ypXKqC1JvSNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start with minimize \"Classification\" to a veriety of 10 categories, not 71.\n",
        "class_df = pd.DataFrame(df[\"CLASSIFICATION\"].value_counts())\n",
        "class_df[\"CLASSIFICATION\"].sort_values(ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n_A2-RqkmQT",
        "outputId": "f3c321a4-83c0-4f30-e07c-e2b76a58f565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keep the top 9 calssifications and change the rest to \"OTHER\", totaling 10 categories\n",
        "class_categories = class_df[class_df[\"CLASSIFICATION\"] >115].index.to_list()\n",
        "class_changing = int(class_df[class_df['CLASSIFICATION'] < 115][\"CLASSIFICATION\"].sum())\n",
        "n_total = int(class_df['CLASSIFICATION'].sum())\n",
        "print(f\"CLASSIFICATION records being converted to 'OTHER': {class_changing} is {round((class_changing/n_total)*100, 2)}% of the total records\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0ysajXmoskU",
        "outputId": "5a41f33e-6099-4ab9-f4ff-569a7bb3bf1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLASSIFICATION records being converted to 'OTHER': 887 is 2.59% of the total records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"APPLICATION_TYPE\"].value_counts().sort_values(ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmPXGsTSuT38",
        "outputId": "11db44f6-688c-4bfa-f3d5-e5293123119b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keep the top 9 App types and change the rest to \"OTHER\", totaling 10 categories\n",
        "app_type_df = pd.DataFrame(df[\"APPLICATION_TYPE\"].value_counts().sort_values(ascending=False))\n",
        "app_types = app_type_df[app_type_df[\"APPLICATION_TYPE\"]>100].index.to_list()\n",
        "app_changing = int(app_type_df[app_type_df[\"APPLICATION_TYPE\"] < 100].sum())\n",
        "print(f\"APPLICATION_TYPE records being converted to 'OTHER': {app_changing} is {round((app_changing/n_total)*100, 2)}% of the total records\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPJClPqYu3tx",
        "outputId": "db7bcc46-d453-4336-a19c-cc4c6a1fa67f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "APPLICATION_TYPE records being converted to 'OTHER': 120 is 0.35% of the total records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply changes to the data using a new dataframe, so the original remains untouched\n",
        "# if required to be used or modified in a different way\n",
        "df2 = df.copy()\n",
        "df2[\"APPLICATION_TYPE\"] = df2[\"APPLICATION_TYPE\"].apply(lambda x: x if x in app_types else \"OTHER\")\n",
        "df2[\"CLASSIFICATION\"] = df2[\"CLASSIFICATION\"].apply(lambda x: x if x in class_categories else \"OTHER\")\n",
        "df2[\"SPECIAL_CONSIDERATIONS\"] = df2[\"SPECIAL_CONSIDERATIONS\"] == 'Y'  ## converts Y/N to True/False, computer will see as 1/0\n",
        "df2[\"STATUS\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqrPRv8io0GX",
        "outputId": "b4ef5a3b-d00b-4020-e8bc-13cfbc40bfeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    34294\n",
              "0        5\n",
              "Name: STATUS, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Transform the string categories into T/F numerical columns representing each category.\n",
        "# \"APPLICATION_TYPE\", \"AFFILIATION\", \"CLASSIFICATION\", \"USE_CASE\", \"ORGANIZATION\", \"SPECIAL_CONSIDERATIONS\", \"INCOME_AMT\"\n",
        "one_hot_encoded_df = pd.get_dummies(df2, columns=[\"APPLICATION_TYPE\", \"AFFILIATION\", \"CLASSIFICATION\", \"USE_CASE\", \"ORGANIZATION\", \"INCOME_AMT\"])\n",
        "\n",
        "# Name and EIN will be removed for the computation, they will not help\n",
        "# the machine weigh options and metrics, and IS_SUCCESSFULL is our goal.\n",
        "encoded_df = one_hot_encoded_df.drop([\"EIN\", \"NAME\", \"IS_SUCCESSFUL\"], axis=1)\n",
        "encoded_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "mL87P3LOzd3a",
        "outputId": "9c4eba1b-f3d3-41c3-eead-974fc11b0ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       STATUS  SPECIAL_CONSIDERATIONS   ASK_AMT  APPLICATION_TYPE_OTHER  \\\n",
              "0           1                   False      5000                       0   \n",
              "1           1                   False    108590                       0   \n",
              "2           1                   False      5000                       0   \n",
              "3           1                   False      6692                       0   \n",
              "4           1                   False    142590                       0   \n",
              "...       ...                     ...       ...                     ...   \n",
              "34294       1                   False      5000                       0   \n",
              "34295       1                   False      5000                       0   \n",
              "34296       1                   False      5000                       0   \n",
              "34297       1                   False      5000                       0   \n",
              "34298       1                   False  36500179                       0   \n",
              "\n",
              "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
              "0                         1                     0                    0   \n",
              "1                         0                     0                    1   \n",
              "2                         0                     0                    0   \n",
              "3                         0                     0                    1   \n",
              "4                         0                     0                    1   \n",
              "...                     ...                   ...                  ...   \n",
              "34294                     0                     0                    0   \n",
              "34295                     0                     0                    0   \n",
              "34296                     0                     0                    1   \n",
              "34297                     0                     0                    0   \n",
              "34298                     0                     0                    1   \n",
              "\n",
              "       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
              "0                        0                    0                    0  ...   \n",
              "1                        0                    0                    0  ...   \n",
              "2                        0                    1                    0  ...   \n",
              "3                        0                    0                    0  ...   \n",
              "4                        0                    0                    0  ...   \n",
              "...                    ...                  ...                  ...  ...   \n",
              "34294                    1                    0                    0  ...   \n",
              "34295                    1                    0                    0  ...   \n",
              "34296                    0                    0                    0  ...   \n",
              "34297                    0                    1                    0  ...   \n",
              "34298                    0                    0                    0  ...   \n",
              "\n",
              "       ORGANIZATION_Trust  INCOME_AMT_0  INCOME_AMT_1-9999  \\\n",
              "0                       0             1                  0   \n",
              "1                       0             0                  1   \n",
              "2                       0             1                  0   \n",
              "3                       1             0                  0   \n",
              "4                       1             0                  0   \n",
              "...                   ...           ...                ...   \n",
              "34294                   0             1                  0   \n",
              "34295                   0             1                  0   \n",
              "34296                   0             1                  0   \n",
              "34297                   0             1                  0   \n",
              "34298                   0             0                  0   \n",
              "\n",
              "       INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
              "0                           0                         0                   0   \n",
              "1                           0                         0                   0   \n",
              "2                           0                         0                   0   \n",
              "3                           1                         0                   0   \n",
              "4                           0                         1                   0   \n",
              "...                       ...                       ...                 ...   \n",
              "34294                       0                         0                   0   \n",
              "34295                       0                         0                   0   \n",
              "34296                       0                         0                   0   \n",
              "34297                       0                         0                   0   \n",
              "34298                       0                         0                   0   \n",
              "\n",
              "       INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
              "0                     0                       0                0   \n",
              "1                     0                       0                0   \n",
              "2                     0                       0                0   \n",
              "3                     0                       0                0   \n",
              "4                     0                       0                0   \n",
              "...                 ...                     ...              ...   \n",
              "34294                 0                       0                0   \n",
              "34295                 0                       0                0   \n",
              "34296                 0                       0                0   \n",
              "34297                 0                       0                0   \n",
              "34298                 1                       0                0   \n",
              "\n",
              "       INCOME_AMT_5M-10M  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      0  \n",
              "4                      0  \n",
              "...                  ...  \n",
              "34294                  0  \n",
              "34295                  0  \n",
              "34296                  0  \n",
              "34297                  0  \n",
              "34298                  0  \n",
              "\n",
              "[34299 rows x 47 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-502f87c7-4211-4473-a7a4-61c2721932f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>APPLICATION_TYPE_OTHER</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>...</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_0</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>108590</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>6692</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>142590</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>36500179</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows Ã— 47 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-502f87c7-4211-4473-a7a4-61c2721932f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-502f87c7-4211-4473-a7a4-61c2721932f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-502f87c7-4211-4473-a7a4-61c2721932f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the status of the data\n",
        "encoded_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI1AopuKS7Vq",
        "outputId": "36863d0f-1743-410f-a5eb-44c0428db068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34299 entries, 0 to 34298\n",
            "Data columns (total 47 columns):\n",
            " #   Column                        Non-Null Count  Dtype\n",
            "---  ------                        --------------  -----\n",
            " 0   STATUS                        34299 non-null  int64\n",
            " 1   SPECIAL_CONSIDERATIONS        34299 non-null  bool \n",
            " 2   ASK_AMT                       34299 non-null  int64\n",
            " 3   APPLICATION_TYPE_OTHER        34299 non-null  uint8\n",
            " 4   APPLICATION_TYPE_T10          34299 non-null  uint8\n",
            " 5   APPLICATION_TYPE_T19          34299 non-null  uint8\n",
            " 6   APPLICATION_TYPE_T3           34299 non-null  uint8\n",
            " 7   APPLICATION_TYPE_T4           34299 non-null  uint8\n",
            " 8   APPLICATION_TYPE_T5           34299 non-null  uint8\n",
            " 9   APPLICATION_TYPE_T6           34299 non-null  uint8\n",
            " 10  APPLICATION_TYPE_T7           34299 non-null  uint8\n",
            " 11  APPLICATION_TYPE_T8           34299 non-null  uint8\n",
            " 12  APPLICATION_TYPE_T9           34299 non-null  uint8\n",
            " 13  AFFILIATION_CompanySponsored  34299 non-null  uint8\n",
            " 14  AFFILIATION_Family/Parent     34299 non-null  uint8\n",
            " 15  AFFILIATION_Independent       34299 non-null  uint8\n",
            " 16  AFFILIATION_National          34299 non-null  uint8\n",
            " 17  AFFILIATION_Other             34299 non-null  uint8\n",
            " 18  AFFILIATION_Regional          34299 non-null  uint8\n",
            " 19  CLASSIFICATION_C1000          34299 non-null  uint8\n",
            " 20  CLASSIFICATION_C1200          34299 non-null  uint8\n",
            " 21  CLASSIFICATION_C1700          34299 non-null  uint8\n",
            " 22  CLASSIFICATION_C2000          34299 non-null  uint8\n",
            " 23  CLASSIFICATION_C2100          34299 non-null  uint8\n",
            " 24  CLASSIFICATION_C3000          34299 non-null  uint8\n",
            " 25  CLASSIFICATION_C4000          34299 non-null  uint8\n",
            " 26  CLASSIFICATION_C5000          34299 non-null  uint8\n",
            " 27  CLASSIFICATION_C7000          34299 non-null  uint8\n",
            " 28  CLASSIFICATION_OTHER          34299 non-null  uint8\n",
            " 29  USE_CASE_CommunityServ        34299 non-null  uint8\n",
            " 30  USE_CASE_Heathcare            34299 non-null  uint8\n",
            " 31  USE_CASE_Other                34299 non-null  uint8\n",
            " 32  USE_CASE_Preservation         34299 non-null  uint8\n",
            " 33  USE_CASE_ProductDev           34299 non-null  uint8\n",
            " 34  ORGANIZATION_Association      34299 non-null  uint8\n",
            " 35  ORGANIZATION_Co-operative     34299 non-null  uint8\n",
            " 36  ORGANIZATION_Corporation      34299 non-null  uint8\n",
            " 37  ORGANIZATION_Trust            34299 non-null  uint8\n",
            " 38  INCOME_AMT_0                  34299 non-null  uint8\n",
            " 39  INCOME_AMT_1-9999             34299 non-null  uint8\n",
            " 40  INCOME_AMT_10000-24999        34299 non-null  uint8\n",
            " 41  INCOME_AMT_100000-499999      34299 non-null  uint8\n",
            " 42  INCOME_AMT_10M-50M            34299 non-null  uint8\n",
            " 43  INCOME_AMT_1M-5M              34299 non-null  uint8\n",
            " 44  INCOME_AMT_25000-99999        34299 non-null  uint8\n",
            " 45  INCOME_AMT_50M+               34299 non-null  uint8\n",
            " 46  INCOME_AMT_5M-10M             34299 non-null  uint8\n",
            "dtypes: bool(1), int64(2), uint8(44)\n",
            "memory usage: 2.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_df = encoded_df.astype(float)\n",
        "encoded_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfuq-02WUPvS",
        "outputId": "0501cb10-175c-4eec-b7ef-1e3554fe044c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34299 entries, 0 to 34298\n",
            "Data columns (total 47 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   STATUS                        34299 non-null  float64\n",
            " 1   SPECIAL_CONSIDERATIONS        34299 non-null  float64\n",
            " 2   ASK_AMT                       34299 non-null  float64\n",
            " 3   APPLICATION_TYPE_OTHER        34299 non-null  float64\n",
            " 4   APPLICATION_TYPE_T10          34299 non-null  float64\n",
            " 5   APPLICATION_TYPE_T19          34299 non-null  float64\n",
            " 6   APPLICATION_TYPE_T3           34299 non-null  float64\n",
            " 7   APPLICATION_TYPE_T4           34299 non-null  float64\n",
            " 8   APPLICATION_TYPE_T5           34299 non-null  float64\n",
            " 9   APPLICATION_TYPE_T6           34299 non-null  float64\n",
            " 10  APPLICATION_TYPE_T7           34299 non-null  float64\n",
            " 11  APPLICATION_TYPE_T8           34299 non-null  float64\n",
            " 12  APPLICATION_TYPE_T9           34299 non-null  float64\n",
            " 13  AFFILIATION_CompanySponsored  34299 non-null  float64\n",
            " 14  AFFILIATION_Family/Parent     34299 non-null  float64\n",
            " 15  AFFILIATION_Independent       34299 non-null  float64\n",
            " 16  AFFILIATION_National          34299 non-null  float64\n",
            " 17  AFFILIATION_Other             34299 non-null  float64\n",
            " 18  AFFILIATION_Regional          34299 non-null  float64\n",
            " 19  CLASSIFICATION_C1000          34299 non-null  float64\n",
            " 20  CLASSIFICATION_C1200          34299 non-null  float64\n",
            " 21  CLASSIFICATION_C1700          34299 non-null  float64\n",
            " 22  CLASSIFICATION_C2000          34299 non-null  float64\n",
            " 23  CLASSIFICATION_C2100          34299 non-null  float64\n",
            " 24  CLASSIFICATION_C3000          34299 non-null  float64\n",
            " 25  CLASSIFICATION_C4000          34299 non-null  float64\n",
            " 26  CLASSIFICATION_C5000          34299 non-null  float64\n",
            " 27  CLASSIFICATION_C7000          34299 non-null  float64\n",
            " 28  CLASSIFICATION_OTHER          34299 non-null  float64\n",
            " 29  USE_CASE_CommunityServ        34299 non-null  float64\n",
            " 30  USE_CASE_Heathcare            34299 non-null  float64\n",
            " 31  USE_CASE_Other                34299 non-null  float64\n",
            " 32  USE_CASE_Preservation         34299 non-null  float64\n",
            " 33  USE_CASE_ProductDev           34299 non-null  float64\n",
            " 34  ORGANIZATION_Association      34299 non-null  float64\n",
            " 35  ORGANIZATION_Co-operative     34299 non-null  float64\n",
            " 36  ORGANIZATION_Corporation      34299 non-null  float64\n",
            " 37  ORGANIZATION_Trust            34299 non-null  float64\n",
            " 38  INCOME_AMT_0                  34299 non-null  float64\n",
            " 39  INCOME_AMT_1-9999             34299 non-null  float64\n",
            " 40  INCOME_AMT_10000-24999        34299 non-null  float64\n",
            " 41  INCOME_AMT_100000-499999      34299 non-null  float64\n",
            " 42  INCOME_AMT_10M-50M            34299 non-null  float64\n",
            " 43  INCOME_AMT_1M-5M              34299 non-null  float64\n",
            " 44  INCOME_AMT_25000-99999        34299 non-null  float64\n",
            " 45  INCOME_AMT_50M+               34299 non-null  float64\n",
            " 46  INCOME_AMT_5M-10M             34299 non-null  float64\n",
            "dtypes: float64(47)\n",
            "memory usage: 12.3 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# does the data need scaled?\n",
        "encoded_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "EgsDk0zvRh1_",
        "outputId": "21248fee-c519-4b16-d694-d2b289004f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             STATUS  SPECIAL_CONSIDERATIONS       ASK_AMT  \\\n",
              "count  34299.000000            34299.000000  3.429900e+04   \n",
              "mean       0.999854                0.000787  2.769199e+06   \n",
              "std        0.012073                0.028046  8.713045e+07   \n",
              "min        0.000000                0.000000  5.000000e+03   \n",
              "25%        1.000000                0.000000  5.000000e+03   \n",
              "50%        1.000000                0.000000  5.000000e+03   \n",
              "75%        1.000000                0.000000  7.742000e+03   \n",
              "max        1.000000                1.000000  8.597806e+09   \n",
              "\n",
              "       APPLICATION_TYPE_OTHER  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
              "count            34299.000000          34299.000000          34299.000000   \n",
              "mean                 0.003499              0.015394              0.031050   \n",
              "std                  0.059047              0.123116              0.173457   \n",
              "min                  0.000000              0.000000              0.000000   \n",
              "25%                  0.000000              0.000000              0.000000   \n",
              "50%                  0.000000              0.000000              0.000000   \n",
              "75%                  0.000000              0.000000              0.000000   \n",
              "max                  1.000000              1.000000              1.000000   \n",
              "\n",
              "       APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
              "count         34299.000000         34299.000000         34299.000000   \n",
              "mean              0.788274             0.044958             0.034199   \n",
              "std               0.408538             0.207214             0.181743   \n",
              "min               0.000000             0.000000             0.000000   \n",
              "25%               1.000000             0.000000             0.000000   \n",
              "50%               1.000000             0.000000             0.000000   \n",
              "75%               1.000000             0.000000             0.000000   \n",
              "max               1.000000             1.000000             1.000000   \n",
              "\n",
              "       APPLICATION_TYPE_T6  ...  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
              "count         34299.000000  ...        34299.000000  34299.000000   \n",
              "mean              0.035453  ...            0.685589      0.711041   \n",
              "std               0.184924  ...            0.464288      0.453285   \n",
              "min               0.000000  ...            0.000000      0.000000   \n",
              "25%               0.000000  ...            0.000000      0.000000   \n",
              "50%               0.000000  ...            1.000000      1.000000   \n",
              "75%               0.000000  ...            1.000000      1.000000   \n",
              "max               1.000000  ...            1.000000      1.000000   \n",
              "\n",
              "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "count       34299.000000            34299.000000              34299.000000   \n",
              "mean            0.021225                0.015831                  0.098370   \n",
              "std             0.144136                0.124825                  0.297819   \n",
              "min             0.000000                0.000000                  0.000000   \n",
              "25%             0.000000                0.000000                  0.000000   \n",
              "50%             0.000000                0.000000                  0.000000   \n",
              "75%             0.000000                0.000000                  0.000000   \n",
              "max             1.000000                1.000000                  1.000000   \n",
              "\n",
              "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "count        34299.000000      34299.000000            34299.000000   \n",
              "mean             0.006997          0.027843                0.109245   \n",
              "std              0.083358          0.164526                0.311951   \n",
              "min              0.000000          0.000000                0.000000   \n",
              "25%              0.000000          0.000000                0.000000   \n",
              "50%              0.000000          0.000000                0.000000   \n",
              "75%              0.000000          0.000000                0.000000   \n",
              "max              1.000000          1.000000                1.000000   \n",
              "\n",
              "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  \n",
              "count     34299.000000       34299.000000  \n",
              "mean          0.004053           0.005394  \n",
              "std           0.063532           0.073245  \n",
              "min           0.000000           0.000000  \n",
              "25%           0.000000           0.000000  \n",
              "50%           0.000000           0.000000  \n",
              "75%           0.000000           0.000000  \n",
              "max           1.000000           1.000000  \n",
              "\n",
              "[8 rows x 47 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14f689c7-61d7-4c8a-8690-3de10b138c1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>APPLICATION_TYPE_OTHER</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>...</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_0</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>3.429900e+04</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "      <td>34299.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.999854</td>\n",
              "      <td>0.000787</td>\n",
              "      <td>2.769199e+06</td>\n",
              "      <td>0.003499</td>\n",
              "      <td>0.015394</td>\n",
              "      <td>0.031050</td>\n",
              "      <td>0.788274</td>\n",
              "      <td>0.044958</td>\n",
              "      <td>0.034199</td>\n",
              "      <td>0.035453</td>\n",
              "      <td>...</td>\n",
              "      <td>0.685589</td>\n",
              "      <td>0.711041</td>\n",
              "      <td>0.021225</td>\n",
              "      <td>0.015831</td>\n",
              "      <td>0.098370</td>\n",
              "      <td>0.006997</td>\n",
              "      <td>0.027843</td>\n",
              "      <td>0.109245</td>\n",
              "      <td>0.004053</td>\n",
              "      <td>0.005394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.012073</td>\n",
              "      <td>0.028046</td>\n",
              "      <td>8.713045e+07</td>\n",
              "      <td>0.059047</td>\n",
              "      <td>0.123116</td>\n",
              "      <td>0.173457</td>\n",
              "      <td>0.408538</td>\n",
              "      <td>0.207214</td>\n",
              "      <td>0.181743</td>\n",
              "      <td>0.184924</td>\n",
              "      <td>...</td>\n",
              "      <td>0.464288</td>\n",
              "      <td>0.453285</td>\n",
              "      <td>0.144136</td>\n",
              "      <td>0.124825</td>\n",
              "      <td>0.297819</td>\n",
              "      <td>0.083358</td>\n",
              "      <td>0.164526</td>\n",
              "      <td>0.311951</td>\n",
              "      <td>0.063532</td>\n",
              "      <td>0.073245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.742000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.597806e+09</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 47 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14f689c7-61d7-4c8a-8690-3de10b138c1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14f689c7-61d7-4c8a-8690-3de10b138c1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14f689c7-61d7-4c8a-8690-3de10b138c1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## scale the data\n",
        "std_scaled_df = pd.DataFrame(StandardScaler().fit_transform(encoded_df), index=encoded_df.index, columns=encoded_df.columns)\n",
        "std_scaled_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "PE8G8ZDNgEvA",
        "outputId": "a7e60943-7b88-44c0-d253-4f77d92ce27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         STATUS  SPECIAL_CONSIDERATIONS   ASK_AMT  APPLICATION_TYPE_OTHER  \\\n",
              "0      0.012075               -0.028068 -0.031725               -0.059253   \n",
              "1      0.012075               -0.028068 -0.030536               -0.059253   \n",
              "2      0.012075               -0.028068 -0.031725               -0.059253   \n",
              "3      0.012075               -0.028068 -0.031706               -0.059253   \n",
              "4      0.012075               -0.028068 -0.030146               -0.059253   \n",
              "...         ...                     ...       ...                     ...   \n",
              "34294  0.012075               -0.028068 -0.031725               -0.059253   \n",
              "34295  0.012075               -0.028068 -0.031725               -0.059253   \n",
              "34296  0.012075               -0.028068 -0.031725               -0.059253   \n",
              "34297  0.012075               -0.028068 -0.031725               -0.059253   \n",
              "34298  0.012075               -0.028068  0.387138               -0.059253   \n",
              "\n",
              "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
              "0                  7.997514             -0.179013            -1.929528   \n",
              "1                 -0.125039             -0.179013             0.518261   \n",
              "2                 -0.125039             -0.179013            -1.929528   \n",
              "3                 -0.125039             -0.179013             0.518261   \n",
              "4                 -0.125039             -0.179013             0.518261   \n",
              "...                     ...                   ...                  ...   \n",
              "34294             -0.125039             -0.179013            -1.929528   \n",
              "34295             -0.125039             -0.179013            -1.929528   \n",
              "34296             -0.125039             -0.179013             0.518261   \n",
              "34297             -0.125039             -0.179013            -1.929528   \n",
              "34298             -0.125039             -0.179013             0.518261   \n",
              "\n",
              "       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
              "0                -0.216965            -0.188176            -0.191719  ...   \n",
              "1                -0.216965            -0.188176            -0.191719  ...   \n",
              "2                -0.216965             5.314171            -0.191719  ...   \n",
              "3                -0.216965            -0.188176            -0.191719  ...   \n",
              "4                -0.216965            -0.188176            -0.191719  ...   \n",
              "...                    ...                  ...                  ...  ...   \n",
              "34294             4.609034            -0.188176            -0.191719  ...   \n",
              "34295             4.609034            -0.188176            -0.191719  ...   \n",
              "34296            -0.216965            -0.188176            -0.191719  ...   \n",
              "34297            -0.216965             5.314171            -0.191719  ...   \n",
              "34298            -0.216965            -0.188176            -0.191719  ...   \n",
              "\n",
              "       ORGANIZATION_Trust  INCOME_AMT_0  INCOME_AMT_1-9999  \\\n",
              "0               -1.476667      0.637486           -0.14726   \n",
              "1               -1.476667     -1.568662            6.79073   \n",
              "2               -1.476667      0.637486           -0.14726   \n",
              "3                0.677201     -1.568662           -0.14726   \n",
              "4                0.677201     -1.568662           -0.14726   \n",
              "...                   ...           ...                ...   \n",
              "34294           -1.476667      0.637486           -0.14726   \n",
              "34295           -1.476667      0.637486           -0.14726   \n",
              "34296           -1.476667      0.637486           -0.14726   \n",
              "34297           -1.476667      0.637486           -0.14726   \n",
              "34298           -1.476667     -1.568662           -0.14726   \n",
              "\n",
              "       INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
              "0                   -0.126831                 -0.330307           -0.083944   \n",
              "1                   -0.126831                 -0.330307           -0.083944   \n",
              "2                   -0.126831                 -0.330307           -0.083944   \n",
              "3                    7.884526                 -0.330307           -0.083944   \n",
              "4                   -0.126831                  3.027487           -0.083944   \n",
              "...                       ...                       ...                 ...   \n",
              "34294               -0.126831                 -0.330307           -0.083944   \n",
              "34295               -0.126831                 -0.330307           -0.083944   \n",
              "34296               -0.126831                 -0.330307           -0.083944   \n",
              "34297               -0.126831                 -0.330307           -0.083944   \n",
              "34298               -0.126831                 -0.330307           -0.083944   \n",
              "\n",
              "       INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
              "0             -0.169236               -0.350205        -0.063789   \n",
              "1             -0.169236               -0.350205        -0.063789   \n",
              "2             -0.169236               -0.350205        -0.063789   \n",
              "3             -0.169236               -0.350205        -0.063789   \n",
              "4             -0.169236               -0.350205        -0.063789   \n",
              "...                 ...                     ...              ...   \n",
              "34294         -0.169236               -0.350205        -0.063789   \n",
              "34295         -0.169236               -0.350205        -0.063789   \n",
              "34296         -0.169236               -0.350205        -0.063789   \n",
              "34297         -0.169236               -0.350205        -0.063789   \n",
              "34298          5.908907               -0.350205        -0.063789   \n",
              "\n",
              "       INCOME_AMT_5M-10M  \n",
              "0              -0.073641  \n",
              "1              -0.073641  \n",
              "2              -0.073641  \n",
              "3              -0.073641  \n",
              "4              -0.073641  \n",
              "...                  ...  \n",
              "34294          -0.073641  \n",
              "34295          -0.073641  \n",
              "34296          -0.073641  \n",
              "34297          -0.073641  \n",
              "34298          -0.073641  \n",
              "\n",
              "[34299 rows x 47 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a928c67e-2ac8-49c6-82ed-b2288d922550\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>APPLICATION_TYPE_OTHER</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>...</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_0</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.028068</td>\n",
              "      <td>-0.031725</td>\n",
              "      <td>-0.059253</td>\n",
              "      <td>7.997514</td>\n",
              "      <td>-0.179013</td>\n",
              "      <td>-1.929528</td>\n",
              "      <td>-0.216965</td>\n",
              "      <td>-0.188176</td>\n",
              "      <td>-0.191719</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.476667</td>\n",
              "      <td>0.637486</td>\n",
              "      <td>-0.14726</td>\n",
              "      <td>-0.126831</td>\n",
              "      <td>-0.330307</td>\n",
              "      <td>-0.083944</td>\n",
              "      <td>-0.169236</td>\n",
              "      <td>-0.350205</td>\n",
              "      <td>-0.063789</td>\n",
              "      <td>-0.073641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.028068</td>\n",
              "      <td>-0.030536</td>\n",
              "      <td>-0.059253</td>\n",
              "      <td>-0.125039</td>\n",
              "      <td>-0.179013</td>\n",
              "      <td>0.518261</td>\n",
              "      <td>-0.216965</td>\n",
              "      <td>-0.188176</td>\n",
              "      <td>-0.191719</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.476667</td>\n",
              "      <td>-1.568662</td>\n",
              "      <td>6.79073</td>\n",
              "      <td>-0.126831</td>\n",
              "      <td>-0.330307</td>\n",
              "      <td>-0.083944</td>\n",
              "      <td>-0.169236</td>\n",
              "      <td>-0.350205</td>\n",
              "      <td>-0.063789</td>\n",
              "      <td>-0.073641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.028068</td>\n",
              "      <td>-0.031725</td>\n",
              "      <td>-0.059253</td>\n",
              "      <td>-0.125039</td>\n",
              "      <td>-0.179013</td>\n",
              "      <td>-1.929528</td>\n",
              "      <td>-0.216965</td>\n",
              "      <td>5.314171</td>\n",
              "      <td>-0.191719</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.476667</td>\n",
              "      <td>0.637486</td>\n",
              "      <td>-0.14726</td>\n",
              "      <td>-0.126831</td>\n",
              "      <td>-0.330307</td>\n",
              "      <td>-0.083944</td>\n",
              "      <td>-0.169236</td>\n",
              "      <td>-0.350205</td>\n",
              "      <td>-0.063789</td>\n",
              "      <td>-0.073641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.028068</td>\n",
              "      <td>-0.031706</td>\n",
              "      <td>-0.059253</td>\n",
              "      <td>-0.125039</td>\n",
              "      <td>-0.179013</td>\n",
              "      <td>0.518261</td>\n",
              "      <td>-0.216965</td>\n",
              "      <td>-0.188176</td>\n",
              "      <td>-0.191719</td>\n",
              "      <td>...</td>\n",
              "      <td>0.677201</td>\n",
              "      <td>-1.568662</td>\n",
              "      <td>-0.14726</td>\n",
              "      <td>7.884526</td>\n",
              "      <td>-0.330307</td>\n",
              "      <td>-0.083944</td>\n",
              "      <td>-0.169236</td>\n",
              "      <td>-0.350205</td>\n",
              "      <td>-0.063789</td>\n",
              "      <td>-0.073641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.028068</td>\n",
              "      <td>-0.030146</td>\n",
              "      <td>-0.059253</td>\n",
              "      <td>-0.125039</td>\n",
              "      <td>-0.179013</td>\n",
              "      <td>0.518261</td>\n",
              "      <td>-0.216965</td>\n",
              "      <td>-0.188176</td>\n",
              "      <td>-0.191719</td>\n",
              "      <td>...</td>\n",
              "      <td>0.677201</td>\n",
              "      <td>-1.568662</td>\n",
              "      <td>-0.14726</td>\n",
              "      <td>-0.126831</td>\n",
              "      <td>3.027487</td>\n",
              "      <td>-0.083944</td>\n",
              "      <td>-0.169236</td>\n",
              "      <td>-0.350205</td>\n",
              "      <td>-0.063789</td>\n",
              "      <td>-0.073641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.028068</td>\n",
              "      <td>-0.031725</td>\n",
              "      <td>-0.059253</td>\n",
              "      <td>-0.125039</td>\n",
              "      <td>-0.179013</td>\n",
              "      <td>-1.929528</td>\n",
              "      <td>4.609034</td>\n",
              "      <td>-0.188176</td>\n",
              "      <td>-0.191719</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.476667</td>\n",
              "      <td>0.637486</td>\n",
              "      <td>-0.14726</td>\n",
              "      <td>-0.126831</td>\n",
              "      <td>-0.330307</td>\n",
              "      <td>-0.083944</td>\n",
              "      <td>-0.169236</td>\n",
              "      <td>-0.350205</td>\n",
              "      <td>-0.063789</td>\n",
              "      <td>-0.073641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.028068</td>\n",
              "      <td>-0.031725</td>\n",
              "      <td>-0.059253</td>\n",
              "      <td>-0.125039</td>\n",
              "      <td>-0.179013</td>\n",
              "      <td>-1.929528</td>\n",
              "      <td>4.609034</td>\n",
              "      <td>-0.188176</td>\n",
              "      <td>-0.191719</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.476667</td>\n",
              "      <td>0.637486</td>\n",
              "      <td>-0.14726</td>\n",
              "      <td>-0.126831</td>\n",
              "      <td>-0.330307</td>\n",
              "      <td>-0.083944</td>\n",
              "      <td>-0.169236</td>\n",
              "      <td>-0.350205</td>\n",
              "      <td>-0.063789</td>\n",
              "      <td>-0.073641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.028068</td>\n",
              "      <td>-0.031725</td>\n",
              "      <td>-0.059253</td>\n",
              "      <td>-0.125039</td>\n",
              "      <td>-0.179013</td>\n",
              "      <td>0.518261</td>\n",
              "      <td>-0.216965</td>\n",
              "      <td>-0.188176</td>\n",
              "      <td>-0.191719</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.476667</td>\n",
              "      <td>0.637486</td>\n",
              "      <td>-0.14726</td>\n",
              "      <td>-0.126831</td>\n",
              "      <td>-0.330307</td>\n",
              "      <td>-0.083944</td>\n",
              "      <td>-0.169236</td>\n",
              "      <td>-0.350205</td>\n",
              "      <td>-0.063789</td>\n",
              "      <td>-0.073641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.028068</td>\n",
              "      <td>-0.031725</td>\n",
              "      <td>-0.059253</td>\n",
              "      <td>-0.125039</td>\n",
              "      <td>-0.179013</td>\n",
              "      <td>-1.929528</td>\n",
              "      <td>-0.216965</td>\n",
              "      <td>5.314171</td>\n",
              "      <td>-0.191719</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.476667</td>\n",
              "      <td>0.637486</td>\n",
              "      <td>-0.14726</td>\n",
              "      <td>-0.126831</td>\n",
              "      <td>-0.330307</td>\n",
              "      <td>-0.083944</td>\n",
              "      <td>-0.169236</td>\n",
              "      <td>-0.350205</td>\n",
              "      <td>-0.063789</td>\n",
              "      <td>-0.073641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.028068</td>\n",
              "      <td>0.387138</td>\n",
              "      <td>-0.059253</td>\n",
              "      <td>-0.125039</td>\n",
              "      <td>-0.179013</td>\n",
              "      <td>0.518261</td>\n",
              "      <td>-0.216965</td>\n",
              "      <td>-0.188176</td>\n",
              "      <td>-0.191719</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.476667</td>\n",
              "      <td>-1.568662</td>\n",
              "      <td>-0.14726</td>\n",
              "      <td>-0.126831</td>\n",
              "      <td>-0.330307</td>\n",
              "      <td>-0.083944</td>\n",
              "      <td>5.908907</td>\n",
              "      <td>-0.350205</td>\n",
              "      <td>-0.063789</td>\n",
              "      <td>-0.073641</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows Ã— 47 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a928c67e-2ac8-49c6-82ed-b2288d922550')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a928c67e-2ac8-49c6-82ed-b2288d922550 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a928c67e-2ac8-49c6-82ed-b2288d922550');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## test_train_split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(std_scaled_df, df[\"IS_SUCCESSFUL\"])\n"
      ],
      "metadata": {
        "id": "R5Qv93rF0d8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total number of input dimensions\n",
        "input_dims = len(std_scaled_df.columns)\n",
        "input_dims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CcHCRJsFUjG",
        "outputId": "2e45f680-94ac-41ee-f560-19e56df58fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build The Neural Network Model\n",
        "\n",
        "The model will start with 3 hidden layers and one known output layer. After some testing of the model, making adjustments \n",
        "\n",
        "The nodes on the hidden layers will be based on the number of inputs and all use the \"tanh\" activation equation.\n",
        "\n",
        "*   Hidden Layer one: input*1.25\n",
        "*   Hidden Layer two: input*1.75\n",
        "*   Hidden Layer three: input/2\n",
        "\n"
      ],
      "metadata": {
        "id": "Qqu8PmUbsd2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## directory for storing the checkpoints generated by the nn model\n",
        "os.makedirs(os.path.join(\"checkpoints\"), exist_ok=True)\n",
        "checkpoint_filepath = os.path.join(\"checkpoints\", \"weights.{epoch:02d}.hdf5\")"
      ],
      "metadata": {
        "id": "DVpVRW0e70Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the checkpoint function to save the weights\n",
        "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, verbose=1, save_weights_only=True, save_freq=\"epoch\")"
      ],
      "metadata": {
        "id": "TYIsItt6Py0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## The Meat of the Neural Network Model\n",
        "keras_model = tf.keras.models.Sequential()\n",
        "\n",
        "## Hidden Layers\n",
        "keras_model.add(tf.keras.layers.Dense(units=int(input_dims*1.25), activation=\"tanh\", input_dim=input_dims))  ## input and hidden layer 1\n",
        "keras_model.add(tf.keras.layers.Dense(units=int(input_dims*1.75), activation=\"tanh\"))  ## hidden layer 2\n",
        "keras_model.add(tf.keras.layers.Dense(units=int(input_dims/2), activation=\"tanh\"))  ## hidden layer 3\n",
        "\n",
        "## This is the known output layer, \n",
        "## we want only T/F statements, that is why sigmoid was chosen.\n",
        "keras_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "keras_model.summary()"
      ],
      "metadata": {
        "id": "WiKOGeCDhKhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd126ec-f0e1-4018-d8eb-5bfe59a41da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 58)                2784      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 82)                4838      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 23)                1909      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,555\n",
            "Trainable params: 9,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "BY80tQlSqv7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitted_model = keras_model.fit(X_train, y_train, epochs=100, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIvzngZct7oG",
        "outputId": "db2c8992-eaa8-468d-b127-57b1c98d78bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "799/804 [============================>.] - ETA: 0s - loss: 0.5683 - accuracy: 0.7209\n",
            "Epoch 1: saving model to checkpoints/weights.01.hdf5\n",
            "804/804 [==============================] - 2s 1ms/step - loss: 0.5683 - accuracy: 0.7208\n",
            "Epoch 2/100\n",
            "798/804 [============================>.] - ETA: 0s - loss: 0.5547 - accuracy: 0.7300\n",
            "Epoch 2: saving model to checkpoints/weights.02.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5551 - accuracy: 0.7296\n",
            "Epoch 3/100\n",
            "799/804 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.7305\n",
            "Epoch 3: saving model to checkpoints/weights.03.hdf5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5502 - accuracy: 0.7303\n",
            "Epoch 4/100\n",
            "795/804 [============================>.] - ETA: 0s - loss: 0.5486 - accuracy: 0.7304\n",
            "Epoch 4: saving model to checkpoints/weights.04.hdf5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5485 - accuracy: 0.7308\n",
            "Epoch 5/100\n",
            "788/804 [============================>.] - ETA: 0s - loss: 0.5464 - accuracy: 0.7322\n",
            "Epoch 5: saving model to checkpoints/weights.05.hdf5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7320\n",
            "Epoch 6/100\n",
            "775/804 [===========================>..] - ETA: 0s - loss: 0.5455 - accuracy: 0.7331\n",
            "Epoch 6: saving model to checkpoints/weights.06.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7332\n",
            "Epoch 7/100\n",
            "771/804 [===========================>..] - ETA: 0s - loss: 0.5444 - accuracy: 0.7342\n",
            "Epoch 7: saving model to checkpoints/weights.07.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7343\n",
            "Epoch 8/100\n",
            "790/804 [============================>.] - ETA: 0s - loss: 0.5434 - accuracy: 0.7344\n",
            "Epoch 8: saving model to checkpoints/weights.08.hdf5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7345\n",
            "Epoch 9/100\n",
            "798/804 [============================>.] - ETA: 0s - loss: 0.5428 - accuracy: 0.7348\n",
            "Epoch 9: saving model to checkpoints/weights.09.hdf5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7349\n",
            "Epoch 10/100\n",
            "788/804 [============================>.] - ETA: 0s - loss: 0.5425 - accuracy: 0.7329\n",
            "Epoch 10: saving model to checkpoints/weights.10.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7333\n",
            "Epoch 11/100\n",
            "778/804 [============================>.] - ETA: 0s - loss: 0.5412 - accuracy: 0.7346\n",
            "Epoch 11: saving model to checkpoints/weights.11.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7344\n",
            "Epoch 12/100\n",
            "764/804 [===========================>..] - ETA: 0s - loss: 0.5401 - accuracy: 0.7368\n",
            "Epoch 12: saving model to checkpoints/weights.12.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.7370\n",
            "Epoch 13/100\n",
            "784/804 [============================>.] - ETA: 0s - loss: 0.5395 - accuracy: 0.7358\n",
            "Epoch 13: saving model to checkpoints/weights.13.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.7353\n",
            "Epoch 14/100\n",
            "769/804 [===========================>..] - ETA: 0s - loss: 0.5392 - accuracy: 0.7359\n",
            "Epoch 14: saving model to checkpoints/weights.14.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7359\n",
            "Epoch 15/100\n",
            "793/804 [============================>.] - ETA: 0s - loss: 0.5386 - accuracy: 0.7371\n",
            "Epoch 15: saving model to checkpoints/weights.15.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7371\n",
            "Epoch 16/100\n",
            "762/804 [===========================>..] - ETA: 0s - loss: 0.5398 - accuracy: 0.7375\n",
            "Epoch 16: saving model to checkpoints/weights.16.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7382\n",
            "Epoch 17/100\n",
            "789/804 [============================>.] - ETA: 0s - loss: 0.5377 - accuracy: 0.7384\n",
            "Epoch 17: saving model to checkpoints/weights.17.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7379\n",
            "Epoch 18/100\n",
            "771/804 [===========================>..] - ETA: 0s - loss: 0.5365 - accuracy: 0.7387\n",
            "Epoch 18: saving model to checkpoints/weights.18.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7382\n",
            "Epoch 19/100\n",
            "787/804 [============================>.] - ETA: 0s - loss: 0.5370 - accuracy: 0.7383\n",
            "Epoch 19: saving model to checkpoints/weights.19.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7379\n",
            "Epoch 20/100\n",
            "785/804 [============================>.] - ETA: 0s - loss: 0.5368 - accuracy: 0.7393\n",
            "Epoch 20: saving model to checkpoints/weights.20.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7390\n",
            "Epoch 21/100\n",
            "803/804 [============================>.] - ETA: 0s - loss: 0.5367 - accuracy: 0.7393\n",
            "Epoch 21: saving model to checkpoints/weights.21.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7392\n",
            "Epoch 22/100\n",
            "792/804 [============================>.] - ETA: 0s - loss: 0.5360 - accuracy: 0.7386\n",
            "Epoch 22: saving model to checkpoints/weights.22.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7379\n",
            "Epoch 23/100\n",
            "769/804 [===========================>..] - ETA: 0s - loss: 0.5360 - accuracy: 0.7386\n",
            "Epoch 23: saving model to checkpoints/weights.23.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7385\n",
            "Epoch 24/100\n",
            "798/804 [============================>.] - ETA: 0s - loss: 0.5361 - accuracy: 0.7389\n",
            "Epoch 24: saving model to checkpoints/weights.24.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7389\n",
            "Epoch 25/100\n",
            "781/804 [============================>.] - ETA: 0s - loss: 0.5357 - accuracy: 0.7383\n",
            "Epoch 25: saving model to checkpoints/weights.25.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7388\n",
            "Epoch 26/100\n",
            "799/804 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.7389\n",
            "Epoch 26: saving model to checkpoints/weights.26.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7390\n",
            "Epoch 27/100\n",
            "802/804 [============================>.] - ETA: 0s - loss: 0.5357 - accuracy: 0.7381\n",
            "Epoch 27: saving model to checkpoints/weights.27.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7383\n",
            "Epoch 28/100\n",
            "784/804 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.7388\n",
            "Epoch 28: saving model to checkpoints/weights.28.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7389\n",
            "Epoch 29/100\n",
            "798/804 [============================>.] - ETA: 0s - loss: 0.5348 - accuracy: 0.7391\n",
            "Epoch 29: saving model to checkpoints/weights.29.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7390\n",
            "Epoch 30/100\n",
            "798/804 [============================>.] - ETA: 0s - loss: 0.5343 - accuracy: 0.7399\n",
            "Epoch 30: saving model to checkpoints/weights.30.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7399\n",
            "Epoch 31/100\n",
            "788/804 [============================>.] - ETA: 0s - loss: 0.5349 - accuracy: 0.7389\n",
            "Epoch 31: saving model to checkpoints/weights.31.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7397\n",
            "Epoch 32/100\n",
            "795/804 [============================>.] - ETA: 0s - loss: 0.5341 - accuracy: 0.7403\n",
            "Epoch 32: saving model to checkpoints/weights.32.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5341 - accuracy: 0.7403\n",
            "Epoch 33/100\n",
            "778/804 [============================>.] - ETA: 0s - loss: 0.5339 - accuracy: 0.7382\n",
            "Epoch 33: saving model to checkpoints/weights.33.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5338 - accuracy: 0.7388\n",
            "Epoch 34/100\n",
            "802/804 [============================>.] - ETA: 0s - loss: 0.5337 - accuracy: 0.7394\n",
            "Epoch 34: saving model to checkpoints/weights.34.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5340 - accuracy: 0.7392\n",
            "Epoch 35/100\n",
            "791/804 [============================>.] - ETA: 0s - loss: 0.5338 - accuracy: 0.7393\n",
            "Epoch 35: saving model to checkpoints/weights.35.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5338 - accuracy: 0.7394\n",
            "Epoch 36/100\n",
            "786/804 [============================>.] - ETA: 0s - loss: 0.5335 - accuracy: 0.7384\n",
            "Epoch 36: saving model to checkpoints/weights.36.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7388\n",
            "Epoch 37/100\n",
            "786/804 [============================>.] - ETA: 0s - loss: 0.5335 - accuracy: 0.7398\n",
            "Epoch 37: saving model to checkpoints/weights.37.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5337 - accuracy: 0.7397\n",
            "Epoch 38/100\n",
            "765/804 [===========================>..] - ETA: 0s - loss: 0.5329 - accuracy: 0.7395\n",
            "Epoch 38: saving model to checkpoints/weights.38.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.7388\n",
            "Epoch 39/100\n",
            "772/804 [===========================>..] - ETA: 0s - loss: 0.5317 - accuracy: 0.7409\n",
            "Epoch 39: saving model to checkpoints/weights.39.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.7394\n",
            "Epoch 40/100\n",
            "770/804 [===========================>..] - ETA: 0s - loss: 0.5335 - accuracy: 0.7399\n",
            "Epoch 40: saving model to checkpoints/weights.40.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5329 - accuracy: 0.7398\n",
            "Epoch 41/100\n",
            "784/804 [============================>.] - ETA: 0s - loss: 0.5329 - accuracy: 0.7393\n",
            "Epoch 41: saving model to checkpoints/weights.41.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5328 - accuracy: 0.7392\n",
            "Epoch 42/100\n",
            "798/804 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.7409\n",
            "Epoch 42: saving model to checkpoints/weights.42.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5325 - accuracy: 0.7406\n",
            "Epoch 43/100\n",
            "785/804 [============================>.] - ETA: 0s - loss: 0.5328 - accuracy: 0.7401\n",
            "Epoch 43: saving model to checkpoints/weights.43.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5324 - accuracy: 0.7400\n",
            "Epoch 44/100\n",
            "771/804 [===========================>..] - ETA: 0s - loss: 0.5318 - accuracy: 0.7408\n",
            "Epoch 44: saving model to checkpoints/weights.44.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5324 - accuracy: 0.7402\n",
            "Epoch 45/100\n",
            "789/804 [============================>.] - ETA: 0s - loss: 0.5325 - accuracy: 0.7409\n",
            "Epoch 45: saving model to checkpoints/weights.45.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5324 - accuracy: 0.7409\n",
            "Epoch 46/100\n",
            "785/804 [============================>.] - ETA: 0s - loss: 0.5327 - accuracy: 0.7380\n",
            "Epoch 46: saving model to checkpoints/weights.46.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5324 - accuracy: 0.7385\n",
            "Epoch 47/100\n",
            "800/804 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.7391\n",
            "Epoch 47: saving model to checkpoints/weights.47.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5321 - accuracy: 0.7393\n",
            "Epoch 48/100\n",
            "776/804 [===========================>..] - ETA: 0s - loss: 0.5330 - accuracy: 0.7393\n",
            "Epoch 48: saving model to checkpoints/weights.48.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5328 - accuracy: 0.7394\n",
            "Epoch 49/100\n",
            "784/804 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.7410\n",
            "Epoch 49: saving model to checkpoints/weights.49.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5317 - accuracy: 0.7411\n",
            "Epoch 50/100\n",
            "770/804 [===========================>..] - ETA: 0s - loss: 0.5318 - accuracy: 0.7404\n",
            "Epoch 50: saving model to checkpoints/weights.50.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5316 - accuracy: 0.7402\n",
            "Epoch 51/100\n",
            "784/804 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.7397\n",
            "Epoch 51: saving model to checkpoints/weights.51.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5316 - accuracy: 0.7401\n",
            "Epoch 52/100\n",
            "781/804 [============================>.] - ETA: 0s - loss: 0.5321 - accuracy: 0.7388\n",
            "Epoch 52: saving model to checkpoints/weights.52.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5314 - accuracy: 0.7394\n",
            "Epoch 53/100\n",
            "794/804 [============================>.] - ETA: 0s - loss: 0.5311 - accuracy: 0.7413\n",
            "Epoch 53: saving model to checkpoints/weights.53.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5316 - accuracy: 0.7406\n",
            "Epoch 54/100\n",
            "783/804 [============================>.] - ETA: 0s - loss: 0.5312 - accuracy: 0.7407\n",
            "Epoch 54: saving model to checkpoints/weights.54.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5313 - accuracy: 0.7408\n",
            "Epoch 55/100\n",
            "775/804 [===========================>..] - ETA: 0s - loss: 0.5313 - accuracy: 0.7417\n",
            "Epoch 55: saving model to checkpoints/weights.55.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5316 - accuracy: 0.7416\n",
            "Epoch 56/100\n",
            "803/804 [============================>.] - ETA: 0s - loss: 0.5315 - accuracy: 0.7405\n",
            "Epoch 56: saving model to checkpoints/weights.56.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5315 - accuracy: 0.7405\n",
            "Epoch 57/100\n",
            "768/804 [===========================>..] - ETA: 0s - loss: 0.5308 - accuracy: 0.7419\n",
            "Epoch 57: saving model to checkpoints/weights.57.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5314 - accuracy: 0.7418\n",
            "Epoch 58/100\n",
            "803/804 [============================>.] - ETA: 0s - loss: 0.5307 - accuracy: 0.7414\n",
            "Epoch 58: saving model to checkpoints/weights.58.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5308 - accuracy: 0.7414\n",
            "Epoch 59/100\n",
            "771/804 [===========================>..] - ETA: 0s - loss: 0.5309 - accuracy: 0.7413\n",
            "Epoch 59: saving model to checkpoints/weights.59.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5308 - accuracy: 0.7412\n",
            "Epoch 60/100\n",
            "794/804 [============================>.] - ETA: 0s - loss: 0.5307 - accuracy: 0.7410\n",
            "Epoch 60: saving model to checkpoints/weights.60.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5306 - accuracy: 0.7408\n",
            "Epoch 61/100\n",
            "770/804 [===========================>..] - ETA: 0s - loss: 0.5303 - accuracy: 0.7417\n",
            "Epoch 61: saving model to checkpoints/weights.61.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5308 - accuracy: 0.7414\n",
            "Epoch 62/100\n",
            "777/804 [===========================>..] - ETA: 0s - loss: 0.5303 - accuracy: 0.7419\n",
            "Epoch 62: saving model to checkpoints/weights.62.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5309 - accuracy: 0.7414\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.5307 - accuracy: 0.7409\n",
            "Epoch 63: saving model to checkpoints/weights.63.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5307 - accuracy: 0.7409\n",
            "Epoch 64/100\n",
            "780/804 [============================>.] - ETA: 0s - loss: 0.5310 - accuracy: 0.7411\n",
            "Epoch 64: saving model to checkpoints/weights.64.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5305 - accuracy: 0.7413\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.7414\n",
            "Epoch 65: saving model to checkpoints/weights.65.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5300 - accuracy: 0.7414\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.7415\n",
            "Epoch 66: saving model to checkpoints/weights.66.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5303 - accuracy: 0.7415\n",
            "Epoch 67/100\n",
            "769/804 [===========================>..] - ETA: 0s - loss: 0.5302 - accuracy: 0.7407\n",
            "Epoch 67: saving model to checkpoints/weights.67.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5307 - accuracy: 0.7399\n",
            "Epoch 68/100\n",
            "764/804 [===========================>..] - ETA: 0s - loss: 0.5306 - accuracy: 0.7411\n",
            "Epoch 68: saving model to checkpoints/weights.68.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5301 - accuracy: 0.7411\n",
            "Epoch 69/100\n",
            "790/804 [============================>.] - ETA: 0s - loss: 0.5303 - accuracy: 0.7412\n",
            "Epoch 69: saving model to checkpoints/weights.69.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5301 - accuracy: 0.7414\n",
            "Epoch 70/100\n",
            "767/804 [===========================>..] - ETA: 0s - loss: 0.5314 - accuracy: 0.7397\n",
            "Epoch 70: saving model to checkpoints/weights.70.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5303 - accuracy: 0.7407\n",
            "Epoch 71/100\n",
            "799/804 [============================>.] - ETA: 0s - loss: 0.5302 - accuracy: 0.7414\n",
            "Epoch 71: saving model to checkpoints/weights.71.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5305 - accuracy: 0.7412\n",
            "Epoch 72/100\n",
            "773/804 [===========================>..] - ETA: 0s - loss: 0.5300 - accuracy: 0.7418\n",
            "Epoch 72: saving model to checkpoints/weights.72.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5303 - accuracy: 0.7416\n",
            "Epoch 73/100\n",
            "778/804 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.7406\n",
            "Epoch 73: saving model to checkpoints/weights.73.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5300 - accuracy: 0.7413\n",
            "Epoch 74/100\n",
            "768/804 [===========================>..] - ETA: 0s - loss: 0.5291 - accuracy: 0.7421\n",
            "Epoch 74: saving model to checkpoints/weights.74.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5301 - accuracy: 0.7416\n",
            "Epoch 75/100\n",
            "769/804 [===========================>..] - ETA: 0s - loss: 0.5308 - accuracy: 0.7415\n",
            "Epoch 75: saving model to checkpoints/weights.75.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5296 - accuracy: 0.7422\n",
            "Epoch 76/100\n",
            "791/804 [============================>.] - ETA: 0s - loss: 0.5306 - accuracy: 0.7406\n",
            "Epoch 76: saving model to checkpoints/weights.76.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5300 - accuracy: 0.7412\n",
            "Epoch 77/100\n",
            "769/804 [===========================>..] - ETA: 0s - loss: 0.5306 - accuracy: 0.7397\n",
            "Epoch 77: saving model to checkpoints/weights.77.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5300 - accuracy: 0.7411\n",
            "Epoch 78/100\n",
            "778/804 [============================>.] - ETA: 0s - loss: 0.5297 - accuracy: 0.7421\n",
            "Epoch 78: saving model to checkpoints/weights.78.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5301 - accuracy: 0.7417\n",
            "Epoch 79/100\n",
            "772/804 [===========================>..] - ETA: 0s - loss: 0.5289 - accuracy: 0.7413\n",
            "Epoch 79: saving model to checkpoints/weights.79.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5296 - accuracy: 0.7414\n",
            "Epoch 80/100\n",
            "797/804 [============================>.] - ETA: 0s - loss: 0.5300 - accuracy: 0.7405\n",
            "Epoch 80: saving model to checkpoints/weights.80.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5298 - accuracy: 0.7404\n",
            "Epoch 81/100\n",
            "782/804 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.7412\n",
            "Epoch 81: saving model to checkpoints/weights.81.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5294 - accuracy: 0.7410\n",
            "Epoch 82/100\n",
            "773/804 [===========================>..] - ETA: 0s - loss: 0.5300 - accuracy: 0.7410\n",
            "Epoch 82: saving model to checkpoints/weights.82.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5299 - accuracy: 0.7413\n",
            "Epoch 83/100\n",
            "778/804 [============================>.] - ETA: 0s - loss: 0.5291 - accuracy: 0.7414\n",
            "Epoch 83: saving model to checkpoints/weights.83.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5293 - accuracy: 0.7416\n",
            "Epoch 84/100\n",
            "785/804 [============================>.] - ETA: 0s - loss: 0.5285 - accuracy: 0.7424\n",
            "Epoch 84: saving model to checkpoints/weights.84.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5296 - accuracy: 0.7418\n",
            "Epoch 85/100\n",
            "777/804 [===========================>..] - ETA: 0s - loss: 0.5305 - accuracy: 0.7412\n",
            "Epoch 85: saving model to checkpoints/weights.85.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5299 - accuracy: 0.7411\n",
            "Epoch 86/100\n",
            "783/804 [============================>.] - ETA: 0s - loss: 0.5292 - accuracy: 0.7419\n",
            "Epoch 86: saving model to checkpoints/weights.86.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5292 - accuracy: 0.7421\n",
            "Epoch 87/100\n",
            "777/804 [===========================>..] - ETA: 0s - loss: 0.5306 - accuracy: 0.7401\n",
            "Epoch 87: saving model to checkpoints/weights.87.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5295 - accuracy: 0.7411\n",
            "Epoch 88/100\n",
            "798/804 [============================>.] - ETA: 0s - loss: 0.5293 - accuracy: 0.7407\n",
            "Epoch 88: saving model to checkpoints/weights.88.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7410\n",
            "Epoch 89/100\n",
            "771/804 [===========================>..] - ETA: 0s - loss: 0.5305 - accuracy: 0.7404\n",
            "Epoch 89: saving model to checkpoints/weights.89.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5293 - accuracy: 0.7410\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.5293 - accuracy: 0.7416\n",
            "Epoch 90: saving model to checkpoints/weights.90.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5293 - accuracy: 0.7416\n",
            "Epoch 91/100\n",
            "782/804 [============================>.] - ETA: 0s - loss: 0.5293 - accuracy: 0.7418\n",
            "Epoch 91: saving model to checkpoints/weights.91.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5294 - accuracy: 0.7418\n",
            "Epoch 92/100\n",
            "789/804 [============================>.] - ETA: 0s - loss: 0.5297 - accuracy: 0.7413\n",
            "Epoch 92: saving model to checkpoints/weights.92.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5292 - accuracy: 0.7416\n",
            "Epoch 93/100\n",
            "781/804 [============================>.] - ETA: 0s - loss: 0.5295 - accuracy: 0.7406\n",
            "Epoch 93: saving model to checkpoints/weights.93.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7410\n",
            "Epoch 94/100\n",
            "779/804 [============================>.] - ETA: 0s - loss: 0.5280 - accuracy: 0.7419\n",
            "Epoch 94: saving model to checkpoints/weights.94.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5286 - accuracy: 0.7416\n",
            "Epoch 95/100\n",
            "803/804 [============================>.] - ETA: 0s - loss: 0.5289 - accuracy: 0.7420\n",
            "Epoch 95: saving model to checkpoints/weights.95.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5289 - accuracy: 0.7420\n",
            "Epoch 96/100\n",
            "794/804 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.7413\n",
            "Epoch 96: saving model to checkpoints/weights.96.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7416\n",
            "Epoch 97/100\n",
            "799/804 [============================>.] - ETA: 0s - loss: 0.5285 - accuracy: 0.7420\n",
            "Epoch 97: saving model to checkpoints/weights.97.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5287 - accuracy: 0.7418\n",
            "Epoch 98/100\n",
            "785/804 [============================>.] - ETA: 0s - loss: 0.5281 - accuracy: 0.7424\n",
            "Epoch 98: saving model to checkpoints/weights.98.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5285 - accuracy: 0.7419\n",
            "Epoch 99/100\n",
            "795/804 [============================>.] - ETA: 0s - loss: 0.5291 - accuracy: 0.7413\n",
            "Epoch 99: saving model to checkpoints/weights.99.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5292 - accuracy: 0.7413\n",
            "Epoch 100/100\n",
            "789/804 [============================>.] - ETA: 0s - loss: 0.5282 - accuracy: 0.7421\n",
            "Epoch 100: saving model to checkpoints/weights.100.hdf5\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5289 - accuracy: 0.7418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pandas.plotting import boxplot\n",
        "fitted_df = pd.DataFrame(fitted_model.history)\n",
        "fitted_df.plot(y=\"accuracy\", kind=\"line\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "emuAS5aC5XTb",
        "outputId": "f66a6faa-a4af-4c57-8487-70dc3cdfc23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f37f5cc6fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fitted_df.plot(y=\"loss\", kind='line')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "7kHL5ZU-g05g",
        "outputId": "d8f7fa1c-bd6d-41f2-f075-59c1cbb0b998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f37f5bac250>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nn_model.evaluate(X_test, y_test)\n",
        "model_loss, model_accuracy = keras_model.evaluate(X_test,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkqluww00JVb",
        "outputId": "675ccf8c-ff99-4e1a-fb4f-1bb44dc84dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5610 - accuracy: 0.7287 - 324ms/epoch - 1ms/step\n",
            "Loss: 0.5609843730926514, Accuracy: 0.7287463545799255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BW__23uAqYUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find an Optimized version of the Neural Network Model.\n",
        "\n",
        "The goal at this point is to be at or above 75% accuracy, the model at this point provides 72.87% accuracy with the testing data. This will be attempted in a seperate ipynb notebook.\n",
        "\n",
        "*   The first attemt to optimize the model will be to use the Keras Tuner to find the best number of hidden layers and neurons.\n",
        "   *    Minimum number of hidden layers: 2\n",
        "   *    Maximum number of hidden layers: 6  \n",
        "   *    Minimum number of neurons per layer: 1\n",
        "   *    Maximum number of neurons per layer: input_dims * 1.75 \n",
        "   *    Test the top 3 models the Keras Tuner finds and train them again with 500 epochs before evaluating them with the test data.\n",
        "*   The second attempt will be to adjust the Keras Tuner for the ability to have multiple activation equations in the hidden layers.\n",
        "\n"
      ],
      "metadata": {
        "id": "4MBMyzSIOvYU"
      }
    }
  ]
}